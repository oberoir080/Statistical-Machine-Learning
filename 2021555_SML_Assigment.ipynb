{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:"
      ],
      "metadata": {
        "id": "RpgBBpsYl0NS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.io import arff\n",
        "from scipy.stats import chi2\n",
        "\n",
        "df = pd.read_csv(\"glass.csv\")\n",
        "# df = pd.DataFrame(data[0])\n",
        "# df = df.sample(n=5000, random_state=42)\n",
        "\n",
        "# print(df.shape)\n",
        "\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "data = df[num_cols]\n",
        "\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "def LOF(X, k):\n",
        "    # Compute pairwise Euclidean distances between points\n",
        "    D = cdist(X, X)\n",
        "    \n",
        "    # Get indices of k nearest neighbors for each point\n",
        "    knn_indices = np.argsort(D, axis=1)[:, 1:k+1]\n",
        "    \n",
        "    RD = np.zeros(X.shape[0])\n",
        "    for i in range(X.shape[0]):\n",
        "        xi = X[i]\n",
        "        x_knn_indices = knn_indices[i]\n",
        "        for j in x_knn_indices:\n",
        "            xj = X[j]\n",
        "            dist = np.linalg.norm(xi - xj)\n",
        "            RD[i] += max(dist, np.max(D[j, x_knn_indices]))\n",
        "        RD[i] /= k\n",
        "    \n",
        "    # Compute Local Reachability Density (LRD) for each point\n",
        "    LRD = 1 / (np.sum(RD[knn_indices], axis=1) / k)\n",
        "    \n",
        "    LOF = np.zeros(X.shape[0])\n",
        "    for i in range(X.shape[0]):\n",
        "        xi = X[i]\n",
        "        x_knn_indices = knn_indices[i]\n",
        "        LOF[i] = np.sum(LRD[x_knn_indices]) / (LRD[i] * k)\n",
        "        \n",
        "    return LOF\n",
        "\n",
        "\n",
        "def MahalonobisDist(x, data, cov=None):\n",
        "    x_mean = x - np.mean(data, axis=0)\n",
        "    if not cov:\n",
        "        cov = np.cov(data.values.T)\n",
        "    inv_covmat = np.linalg.inv(cov)\n",
        "    left = np.dot(x_mean, inv_covmat)\n",
        "    mahalonobis = np.dot(left, x_mean.T)\n",
        "    \n",
        "    return mahalonobis.diagonal()\n",
        "\n",
        "df[\"mahalonobis\"] = MahalonobisDist(df[num_cols], data)\n",
        "df['p'] = 1 - chi2.cdf(df['mahalonobis'], 28)\n",
        "\n",
        "# print(df.head())\n",
        "print(df[df['p'] < 0.001])\n",
        "\n",
        "num_cols = df.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "# Compute LOF scores\n",
        "X = df[num_cols].values\n",
        "k = 20\n",
        "lof_scores = LOF(X, k)\n",
        "\n",
        "# Add LOF scores to dataframe\n",
        "df['lof_score'] = lof_scores\n",
        "\n",
        "outliers = df[df['lof_score'] > 1.5]\n",
        "print(\"Number of outliers detected:\", outliers.shape[0])\n",
        "print(outliers)\n",
        "\n",
        "\n",
        "def otsu_threshold(data):\n",
        "    hist, bins = np.histogram(data, bins=256, range=(0, 255))\n",
        "    hist_norm = hist.astype(np.float32) / hist.sum()\n",
        "    bin_centers = (bins[:-1] + bins[1:]) / 2.\n",
        "\n",
        "    # Computing inter-class variance for all possible thresholds\n",
        "    weight_background = np.cumsum(hist_norm)\n",
        "    mean_background = np.cumsum(hist_norm * bin_centers) / weight_background\n",
        "    mean_foreground = np.cumsum((hist_norm * bin_centers)[::-1])[::-1] / (1 - weight_background)\n",
        "\n",
        "    variance_between_classes = weight_background[:-1] * (1 - weight_background[:-1]) * ((mean_background[:-1] - mean_foreground[1:]) ** 2)\n",
        "\n",
        "    # Finding the threshold with maximum inter-class variance\n",
        "    idx_max = np.argmax(variance_between_classes)\n",
        "    threshold = bin_centers[:-1][idx_max]\n",
        "\n",
        "    return threshold\n",
        "\n",
        "\n",
        "# Select a single feature for Otsu's thresholding\n",
        "feature = \"RI\"\n",
        "x = df[feature]\n",
        "\n",
        "thresh = otsu_threshold(x)\n",
        "binary = x > thresh\n",
        "\n",
        "print(\"Otsu's threshold:\", thresh)\n",
        "print(\"Number of pixels above the threshold:\", np.sum(binary))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVyH3L2zl51F",
        "outputId": "713825ed-c034-44fb-c2dd-a53db3135ead"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          RI     Na    Mg    Al     Si     K     Ca    Ba    Fe  Type  \\\n",
            "106  1.53125  10.73  0.00  2.10  69.81  0.58  13.30  3.15  0.28     2   \n",
            "149  1.51643  12.16  3.52  1.35  72.89  0.57   8.53  0.00  0.00     3   \n",
            "171  1.51316  13.02  0.00  3.04  70.48  6.21   6.96  0.00  0.00     5   \n",
            "172  1.51321  13.00  0.00  3.02  70.70  6.21   6.93  0.00  0.00     5   \n",
            "184  1.51115  17.38  0.00  0.34  75.41  0.00   6.65  0.00  0.00     6   \n",
            "\n",
            "     mahalonobis             p  \n",
            "106    87.095612  5.599748e-08  \n",
            "149    63.641306  1.367545e-04  \n",
            "171    87.576067  4.720268e-08  \n",
            "172    87.788275  4.376657e-08  \n",
            "184    65.597294  7.489330e-05  \n",
            "Number of outliers detected: 5\n",
            "          RI     Na    Mg    Al     Si     K     Ca    Ba    Fe  Type  \\\n",
            "106  1.53125  10.73  0.00  2.10  69.81  0.58  13.30  3.15  0.28     2   \n",
            "149  1.51643  12.16  3.52  1.35  72.89  0.57   8.53  0.00  0.00     3   \n",
            "171  1.51316  13.02  0.00  3.04  70.48  6.21   6.96  0.00  0.00     5   \n",
            "172  1.51321  13.00  0.00  3.02  70.70  6.21   6.93  0.00  0.00     5   \n",
            "184  1.51115  17.38  0.00  0.34  75.41  0.00   6.65  0.00  0.00     6   \n",
            "\n",
            "     mahalonobis             p  lof_score  \n",
            "106    87.095612  5.599748e-08   1.600999  \n",
            "149    63.641306  1.367545e-04   1.597628  \n",
            "171    87.576067  4.720268e-08   1.601151  \n",
            "172    87.788275  4.376657e-08   1.601181  \n",
            "184    65.597294  7.489330e-05   1.596045  \n",
            "Otsu's threshold: 0.498046875\n",
            "Number of pixels above the threshold: 214\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-e0db1f34b115>:85: RuntimeWarning: invalid value encountered in true_divide\n",
            "  mean_background = np.cumsum(hist_norm * bin_centers) / weight_background\n",
            "<ipython-input-5-e0db1f34b115>:86: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  mean_foreground = np.cumsum((hist_norm * bin_centers)[::-1])[::-1] / (1 - weight_background)\n",
            "<ipython-input-5-e0db1f34b115>:86: RuntimeWarning: invalid value encountered in true_divide\n",
            "  mean_foreground = np.cumsum((hist_norm * bin_centers)[::-1])[::-1] / (1 - weight_background)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2:"
      ],
      "metadata": {
        "id": "YV-QR6KDl3cM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def predict(X, w):\n",
        "    z = np.clip(X.dot(w), -500, 500) # limit z to avoid overflow\n",
        "    return sigmoid(z)\n",
        "\n",
        "def train(X, y, lr=0.01, epochs=1000):\n",
        "    w = np.zeros(X.shape[1])\n",
        "    for epoch in range(epochs):\n",
        "        y_pred = predict(X, w)\n",
        "        error = y - y_pred\n",
        "        gradient = X.T.dot(error)\n",
        "        w += lr * gradient\n",
        "    return w\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    return np.mean(y_true == y_pred)\n",
        "\n",
        "def main():\n",
        "    # Load data\n",
        "    df = pd.read_csv(\"Heart.csv\", header=0)\n",
        "\n",
        "    df.dropna(inplace=True)\n",
        "    X = df.drop('AHD', axis=1)\n",
        "    y = df['AHD']\n",
        "\n",
        "    # Convert categorical variables to numerical using one-hot encoding\n",
        "    df = pd.get_dummies(df, columns=[\"ChestPain\", \"Thal\"])\n",
        "\n",
        "    X = df.drop([\"AHD\"], axis=1)\n",
        "    y = df[\"AHD\"]\n",
        "\n",
        "    # Convert categorical target variable to numerical\n",
        "    y = pd.get_dummies(y, drop_first=True).values.ravel()\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=19)\n",
        "\n",
        "    from sklearn.decomposition import PCA\n",
        "    # Apply PCA to reduce the feature dimension\n",
        "    pca = PCA(n_components=3)\n",
        "    X_train_transformed_pca = pca.fit_transform(X_train)\n",
        "    X_test_transformed_pca = pca.transform(X_test)\n",
        "\n",
        "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "    lda = LinearDiscriminantAnalysis(n_components=1)\n",
        "    X_train_transformed_fda = lda.fit_transform(X_train_transformed_pca, y_train)\n",
        "    X_test_transformed_fda = lda.transform(X_test_transformed_pca)\n",
        "\n",
        "    # Train logistic regression model without FDA+PCA\n",
        "    w_before = train(X_train, y_train)\n",
        "    y_pred_before = (predict(X_test, w_before) > 0.5).astype(int)\n",
        "    accuracy_before = accuracy(y_test.astype(int), y_pred_before)\n",
        "\n",
        "    print(f\"Accuracy before: {accuracy_before}\")\n",
        "\n",
        "    # Train logistic regression model after FDA+PCA\n",
        "    w_after_fda_pca = train(X_train_transformed_fda, y_train)\n",
        "    y_pred_after_fda_pca = (predict(X_test_transformed_fda, w_after_fda_pca) > 0.5).astype(int)\n",
        "\n",
        "    accuracy_after_fda_pca = accuracy(y_test.astype(int), y_pred_after_fda_pca)\n",
        "\n",
        "    print(f\"Accuracy after PCA+FDA: {accuracy_after_fda_pca}\")\n",
        "\n",
        "    w_after_fda = train(X_train_transformed_fda, y_train)\n",
        "\n",
        "    y_pred_after_fda = (predict(X_test_transformed_fda, w_after_fda) > 0.5).astype(int)\n",
        "\n",
        "    accuracy_after_fda = accuracy(y_test.astype(int), y_pred_after_fda)\n",
        "\n",
        "    print(f\"Accuracy after FDA: {accuracy_after_fda}\")\n",
        "\n",
        "\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVTMcfEwl6Jl",
        "outputId": "880b8687-d5fe-47b2-eb6a-7950faae8007"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy before: 0.55\n",
            "Accuracy after PCA+FDA: 0.7833333333333333\n",
            "Accuracy after FDA: 0.7833333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3:"
      ],
      "metadata": {
        "id": "bL6q3CiEfXD-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import metrics\n",
        "\n",
        "df = pd.read_csv(\"RealEstate.csv\", header=0)\n",
        "df.drop('No', axis=1, inplace=True)\n",
        "\n",
        "df = df.dropna() #It allows to neglect the null values in the data set\n",
        "\n",
        "df.insert(0, 'Ones', 1)\n",
        "\n",
        "X = df.iloc[:, :-1].values\n",
        "y = df.iloc[:, -1].values.reshape(-1, 1)\n",
        "\n",
        "Transposed_X = np.transpose(X)\n",
        "\n",
        "X_Matrix_Multiplied = Transposed_X.dot(X)\n",
        "\n",
        "Inv_X = np.linalg.inv(X_Matrix_Multiplied)\n",
        "\n",
        "X_y_dotProduct = Transposed_X.dot(y)\n",
        "\n",
        "theta = Inv_X.dot(X_y_dotProduct)\n",
        "\n",
        "Intercept = theta[0]\n",
        "slope = theta[1]\n",
        "\n",
        "y_pred = X.dot(theta)\n",
        "rmse = np.sqrt(np.mean((y_pred - y) ** 2))\n",
        "rss = np.sum((y_pred - y) ** 2)\n",
        "tss = np.sum((y - np.mean(y)) ** 2)\n",
        "r2 = 1 - (rss / tss)\n",
        "\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"RSS:\", rss)\n",
        "print(\"R-squared:\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SZvfecWfTni",
        "outputId": "12cef0c1-234d-4aaa-f3a3-438137d92f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 8.782466464603045\n",
            "RSS: 31932.530921577123\n",
            "R-squared: 0.582370447272281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To derive the normal equation, we start by assuming that the linear regression model has the form y = Xθ + ε, where y is the dependent variable, X is the independent variable, θ is a vector of parameters, and ε is the error term.\n",
        "\n",
        "θ = (X^TX)^-1* (X^T*y)\n",
        "\n",
        "The normal equation, which is this expression's counterpart, provides us with the θ parameters' values.\n",
        "\n",
        "This formula is used in the given code to determine the intercept and slope of the linear regression model, which are the values of theta. Theta vector's first element contains the intercept, while its second element contains the slope.\n",
        "\n",
        "The code then computes the RMSE, RSS, and R-squared metrics to assess how well the linear regression model performed on the training set of data.\n",
        "\n",
        "\n",
        "**Limitations of this approach:**\n",
        "We need to compute (X^T*X)-1 and it is very slow if the value of n is very large. "
      ],
      "metadata": {
        "id": "DO3cmKqR2VFr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4:"
      ],
      "metadata": {
        "id": "f59CXNqIfblG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class LDA:\n",
        "    def __init__(self, n_components=None):\n",
        "        self.n_components = n_components\n",
        "        self.w = None\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        classes = np.unique(y)\n",
        "        means = [np.mean(X[y == c], axis=0) for c in classes]\n",
        "        \n",
        "        Sw = np.zeros((X.shape[1], X.shape[1]))\n",
        "        for c in classes:\n",
        "            Xc = X[y == c]\n",
        "            mc = means[c]\n",
        "            for x in Xc:\n",
        "                x = x.reshape(-1, 1)\n",
        "                mc = mc.reshape(-1, 1)\n",
        "                Sw += (x - mc) @ (x - mc).T\n",
        "        \n",
        "        Sb = np.zeros((X.shape[1], X.shape[1]))\n",
        "        for c in classes:\n",
        "            Xc = X[y == c]\n",
        "            mc = means[c]\n",
        "            Nc = Xc.shape[0]\n",
        "            mc = mc.reshape(-1, 1)\n",
        "            m = np.mean(X, axis=0).reshape(-1, 1)\n",
        "            Sb += Nc * (mc - m) @ (mc - m).T\n",
        "        \n",
        "        A = np.linalg.inv(Sw) @ Sb\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(A)\n",
        "        \n",
        "        idx = np.argsort(eigenvalues)[::-1]\n",
        "        eigenvectors = eigenvectors[:, idx]\n",
        "\n",
        "        if self.n_components is not None:\n",
        "            eigenvectors = eigenvectors[:, :self.n_components]\n",
        "        \n",
        "        self.w = eigenvectors\n",
        "    \n",
        "    def transform(self, X):\n",
        "        return X @ self.w\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=8)\n",
        "\n",
        "lda = LDA(n_components=2)\n",
        "lda.fit(X_train, y_train)\n",
        "X_train_lda = lda.transform(X_train)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train_lda, y_train)\n",
        "\n",
        "X_test_lda = lda.transform(X_test)\n",
        "y_pred = knn.predict(X_test_lda)\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {acc:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxX2wLpxevCz",
        "outputId": "8ac6cd37-eb6b-4223-9e23-c1f6dd4aa03d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5:"
      ],
      "metadata": {
        "id": "5_lqkMNIZ-pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def cost(X, y, theta):\n",
        "    m = len(y)\n",
        "    h = sigmoid(np.dot(X, theta))\n",
        "    h = np.clip(h, 0.000001, 0.999999)  \n",
        "    J = (-1/m) * np.sum(y * np.log(h) + (1-y) * np.log(1-h))\n",
        "    return J\n",
        "\n",
        "def gradient_descent(X, y, theta, alpha, epochs):\n",
        "    m = len(y)\n",
        "    J_history = []\n",
        "    for i in range(epochs):\n",
        "        h = sigmoid(np.dot(X, theta))\n",
        "        h = np.clip(h, 0.000001, 0.999999)  \n",
        "        gradient = (1/m) * np.dot(X.T, (h-y))\n",
        "        theta -= alpha * gradient\n",
        "        J_history.append(cost(X, y, theta))\n",
        "    return theta, J_history\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=5, n_informative=3, random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "m, n = X_train.shape\n",
        "theta = np.zeros(n)\n",
        "alpha = 0.01\n",
        "epochs = 1000\n",
        "\n",
        "theta, J_history = gradient_descent(X_train, y_train, theta, alpha, epochs)\n",
        "\n",
        "y_pred_train = sigmoid(np.dot(X_train, theta))\n",
        "y_pred_train = np.clip(y_pred_train, 0.000001, 0.999999)\n",
        "y_pred_train = np.round(y_pred_train)\n",
        "\n",
        "y_pred_test = sigmoid(np.dot(X_test, theta))\n",
        "y_pred_test = np.clip(y_pred_test, 0.000001, 0.999999)\n",
        "y_pred_test = np.round(y_pred_test)\n",
        "\n",
        "acc_train = np.mean(y_pred_train == y_train)\n",
        "acc_test = np.mean(y_pred_test == y_test)\n",
        "\n",
        "print(\"Training accuracy:\", acc_train)\n",
        "print(\"Test accuracy:\", acc_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9ut6IdDZ6rx",
        "outputId": "4d9810a3-6f88-4dcb-c2dd-9bfff458bc96"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.905\n",
            "Test accuracy: 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can apply Logistic Regression to a multi-class classification problem by splitting the problem into multiple binary classification problems. Yes it provided better results than in Question 4 as the accuracy increased by 0.01."
      ],
      "metadata": {
        "id": "YQXi_YyFq5rR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "jQCbbGS2-K9_",
        "outputId": "440db29c-3c2d-4dbd-8b1e-2e54f47a5d06"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d0e69a7e-e4e9-4caf-961d-0d02230ec637\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d0e69a7e-e4e9-4caf-961d-0d02230ec637\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving glass.csv to glass.csv\n"
          ]
        }
      ]
    }
  ]
}